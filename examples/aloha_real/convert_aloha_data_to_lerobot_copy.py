"""
Convert Aloha hdf5 data to LeRobot v2.0 format (compatible with lerobot==0.3.2)

ç‰¹æ€§:
1. è‡ªåŠ¨æ£€æµ‹ image_writer å¹¶å‘å‚æ•°ï¼ˆå°½é‡å¿« & ä¸çˆ†å†…å­˜ï¼‰
2. æ–­ç‚¹ç»­è·‘ï¼šä½¿ç”¨ _progress.json è®°å½•å·²å®Œæˆçš„ episode
3. å•ä¸ª episode å¤±è´¥ä¸ä¼šä¸­æ–­æ•´ä¸ªä»»åŠ¡
"""

import dataclasses
import gc
import json
from pathlib import Path
from typing import Literal, Optional, List

import psutil
import shutil
import io

import h5py
import numpy as np
import cv2
import torch
import tqdm
from PIL import Image

from lerobot.datasets.lerobot_dataset import (
    HF_LEROBOT_HOME as LEROBOT_HOME,
    LeRobotDataset,
)


# ========================
# å¹¶å‘å‚æ•°è‡ªåŠ¨æ£€æµ‹
# ========================

def auto_detect_parallelism() -> tuple[int, int]:
    """
    æ ¹æ®å½“å‰æœºå™¨çš„å†…å­˜ & CPU è‡ªåŠ¨é€‰æ‹©:
    - image_writer_processes
    - image_writer_threads
    """
    print("\nğŸ” Auto-parallel tuning")
    mem = psutil.virtual_memory()
    total_gb = mem.total / 1024 ** 3
    avail_gb = mem.available / 1024 ** 3
    cpu_cores = psutil.cpu_count(logical=False) or psutil.cpu_count(logical=True)

    print(f"ğŸ§  Total RAM: {total_gb:.1f} GB")
    print(f"ğŸ’¾ Available: {avail_gb:.1f} GB")
    print(f"âš™ï¸ CPU cores: {cpu_cores}")

    # ç²—ä¼°ï¼šæ¯å¸§ 480x640x3ï¼Œ4 ä¸ª cameraï¼Œæ’é˜Ÿé•¿åº¦ 8
    frame_bytes = 480 * 640 * 3
    per_frame_mb = frame_bytes * 4 / (1024 * 1024)
    queue_len = 8
    per_proc_mb = per_frame_mb * queue_len

    if per_proc_mb <= 0:
        max_proc_by_mem = 1
    else:
        usable_mb = avail_gb * 1024 * 0.5
        max_proc_by_mem = max(1, int(usable_mb / per_proc_mb))

    procs = min(cpu_cores, max_proc_by_mem) - 2
    procs = max(1, procs)
    threads = 2

    print(f"â†’ image_writer_processes = {procs}")
    print(f"â†’ image_writer_threads   = {threads}\n")

    return procs, threads


# ========================
# Dataset é…ç½®
# ========================

@dataclasses.dataclass(frozen=True)
class DatasetConfig:
    use_videos: bool = True
    tolerance_s: float = 1e-4
    image_writer_processes: Optional[int] = None
    image_writer_threads: Optional[int] = None
    video_backend: Optional[str] = None
    batch_encoding_size: int = 1


_auto_procs, _auto_threads = auto_detect_parallelism()
DEFAULT_DATASET_CONFIG = DatasetConfig(
    image_writer_processes=_auto_procs,
    image_writer_threads=_auto_threads,
)


# ========================
# æ„é€  featuresï¼ˆschemaï¼‰
# ========================

MOTORS = [
    "left_waist",
    "left_shoulder",
    "left_elbow",
    "left_forearm_roll",
    "left_wrist_angle",
    "left_wrist_rotate",
    "left_gripper",
    "right_waist",
    "right_shoulder",
    "right_elbow",
    "right_forearm_roll",
    "right_wrist_angle",
    "right_wrist_rotate",
    "right_gripper",
]

CAMERAS = [
    "cam_high",
    "cam_low",
    "cam_left_wrist",
    "cam_right_wrist",
]


def has_velocity(hdf5_files: List[Path]) -> bool:
    with h5py.File(hdf5_files[0], "r") as ep:
        return "qvel" in ep["observations"]


def has_effort(hdf5_files: List[Path]) -> bool:
    with h5py.File(hdf5_files[0], "r") as ep:
        return "effort" in ep["observations"]


def build_features(
    hdf5_files: List[Path],
    mode: Literal["video", "image"],
) -> dict:
    """
    æ ¹æ® Aloha æ•°æ®ç»“æ„æ„é€  LeRobot çš„ features dictã€‚
    """
    feats: dict = {
        "observation.state": {
            "dtype": "float32",
            "shape": (len(MOTORS),),
            "names": [MOTORS],
        },
        "action": {
            "dtype": "float32",
            "shape": (len(MOTORS),),
            "names": [MOTORS],
        },
    }

    if has_velocity(hdf5_files):
        feats["observation.velocity"] = {
            "dtype": "float32",
            "shape": (len(MOTORS),),
            "names": [MOTORS],
        }

    if has_effort(hdf5_files):
        feats["observation.effort"] = {
            "dtype": "float32",
            "shape": (len(MOTORS),),
            "names": [MOTORS],
        }

    for cam in CAMERAS:
        feats[f"observation.images.{cam}"] = {
            "dtype": mode,  # "image" or "video"
            "shape": (3, 480, 640),
            "names": ["channels", "height", "width"],
        }

    return feats


# ========================
# HDF5 è¯»å–å·¥å…·
# ========================

CAMERA_MAPPING = {
    "cam_high": "camera_high",
    "cam_low": "camera_low",
    "cam_left_wrist": "camera_wrist_left",
    "cam_right_wrist": "camera_wrist_right",
}


def get_camera_image_at_frame(ep: h5py.File, camera: str, frame_idx: int) -> np.ndarray:
    """
    ä» episode æ–‡ä»¶ä¸­è¯»å–æŒ‡å®š camera çš„ç¬¬ frame_idx å¸§å›¾åƒã€‚
    è¿”å›å½¢çŠ¶ (H, W, 3)ï¼Œuint8ï¼ŒBGRï¼ˆOpenCV é£æ ¼ï¼‰ã€‚
    """
    true_name = CAMERA_MAPPING[camera]
    camera_path = f"observations/images/{true_name}"
    ds = ep[camera_path]

    # æœªå‹ç¼©: (T, H, W, C)
    if ds.ndim == 4:
        img = ds[frame_idx].astype(np.uint8)
        return img

    # å‹ç¼©: æ¯å¸§æ˜¯ä¸€ä¸² bytesï¼ˆå­˜æˆ 1D æ•°ç»„ï¼‰
    compressed = ds[frame_idx]
    if isinstance(compressed, np.ndarray):
        compressed = compressed.tobytes()

    with io.BytesIO(compressed) as buff:
        pil_img = Image.open(buff)
        pil_img = pil_img.convert("RGB")
        arr = np.array(pil_img)
        bgr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)

    return bgr


def load_episode(
    ep_path: Path,
):
    """
    æ‰“å¼€ä¸€ä¸ª episodeï¼Œè¿”å›:
    - ep: h5py.File
    - state: (T, 14) torch.float32
    - action: (T, 14) torch.float32
    - velocity: (T, 14) or None
    - effort: (T, 14) or None
    """
    ep = h5py.File(ep_path, "r")

    qpos = ep["observations"]["qpos"][()]  # (T, 14)
    act = ep["action"][()]                 # (T, 14)

    def reorder(x: np.ndarray) -> np.ndarray:
        # æŠŠå³è‡‚ 7 ç»´æ”¾å‰é¢ï¼Œå·¦è‡‚ 7 ç»´æ”¾åé¢
        return np.concatenate([x[:, 7:], x[:, :7]], axis=1)

    state_np = reorder(qpos)
    action_np = reorder(act)

    state = torch.from_numpy(state_np.astype(np.float32))
    action = torch.from_numpy(action_np.astype(np.float32))

    velocity = None
    if "qvel" in ep["observations"]:
        qvel = ep["observations"]["qvel"][()]
        vel_np = reorder(qvel)
        velocity = torch.from_numpy(vel_np.astype(np.float32))

    effort = None
    if "effort" in ep["observations"]:
        qeff = ep["observations"]["effort"][()]
        eff_np = reorder(qeff)
        effort = torch.from_numpy(eff_np.astype(np.float32))

    return ep, state, action, velocity, effort


# ========================
# åˆ›å»º / æ¢å¤ Datasetï¼ˆä¸ä½¿ç”¨ local_only / overwriteï¼‰
# ========================

def safe_open_dataset(repo_id: str,
                      features: dict,
                      fps: int,
                      robot_type: str,
                      dataset_config: DatasetConfig):

    repo_dir = LEROBOT_HOME / repo_id
    progress_file = repo_dir / "_progress.json"

    # --- Case 1: brand new dataset ---
    if not repo_dir.exists():
        print("ğŸ†• Creating new dataset directory")
        return LeRobotDataset.create(
            repo_id=repo_id,
            fps=fps,
            features=features,
            robot_type=robot_type,
            use_videos=dataset_config.use_videos,
            tolerance_s=dataset_config.tolerance_s,
            image_writer_processes=dataset_config.image_writer_processes,
            image_writer_threads=dataset_config.image_writer_threads,
        )

    # --- Case 2: folder exists but no progress file â†’ refuse ---
    if not progress_file.exists():
        raise RuntimeError("Dataset exists but _progress.json missing â†’ cannot resume safely")

    # --- Case 3: RESUME ---
    print("ğŸ” RESUME mode â†’ loading dataset instead of creating")
    return LeRobotDataset(repo_id)


# ========================
# ä¸»è½¬æ¢é€»è¾‘ + æ–­ç‚¹ç»­è·‘
# ========================

def populate_dataset(
    dataset: LeRobotDataset,
    hdf5_files: List[Path],
    task: str,
    repo_id: str,
    episodes: Optional[List[int]] = None,
) -> LeRobotDataset:
    """
    éå† HDF5 æ–‡ä»¶ï¼Œå¡«å…… LeRobotDatasetã€‚
    ä½¿ç”¨ _progress.json è®°å½•å·²å®Œæˆçš„ episodeï¼Œæ”¯æŒæ–­ç‚¹ç»­è·‘ã€‚
    """
    if episodes is None:
        episodes = list(range(len(hdf5_files)))

    dataset_root = LEROBOT_HOME / repo_id
    progress_path = dataset_root / "_progress.json"

    finished: set[int] = set()
    if progress_path.exists():
        try:
            data = json.loads(progress_path.read_text())
            finished = set(data.get("finished", []))
            print(f"ğŸ” Resume: already finished episodes: {sorted(finished)}")
        except Exception as e:
            print(f"âš ï¸ Failed to read progress file: {e}")

    process = psutil.Process()
    prev_mem_gb = process.memory_info().rss / (1024 ** 3)

    for ep_idx in tqdm.tqdm(episodes, desc="Episodes"):
        if ep_idx in finished:
            print(f"â­  Skip episode {ep_idx} (already done)")
            continue

        ep_path = hdf5_files[ep_idx]
        print(f"\nâ–¶ï¸  Start processing episode {ep_idx}: {ep_path}")

        try:
            ep, state, action, velocity, effort = load_episode(ep_path)
        except Exception as e:
            print(f"âŒ Failed to load episode {ep_idx}: {e}")
            continue

        num_frames = state.shape[0]
        cams = CAMERAS

        for i in range(num_frames):
            frame = {
                "observation.state": state[i],
                "action": action[i],
            }

            if velocity is not None:
                frame["observation.velocity"] = velocity[i]
            if effort is not None:
                frame["observation.effort"] = effort[i]

            # è¯»å– 4 ä¸ªç›¸æœºå›¾åƒ
            ok = True
            for cam in cams:
                try:
                    img = get_camera_image_at_frame(ep, cam, i)
                except Exception as e:
                    print(f"âš ï¸  Episode {ep_idx} frame {i} camera {cam} failed: {e}")
                    ok = False
                    break
                frame[f"observation.images.{cam}"] = img

            if not ok:
                # è¿™ä¸€å¸§æœ‰é—®é¢˜ï¼Œç›´æ¥è·³è¿‡ï¼ˆä¸å†™å…¥ datasetï¼‰
                continue

            dataset.add_frame(frame, task)
            del frame

            if i % 50 == 0:
                gc.collect()

        # å®Œæˆä¸€ä¸ª episode
        try:
            dataset.save_episode()
        except Exception as e:
            print(f"âŒ save_episode failed for episode {ep_idx}: {e}")
        finally:
            ep.close()
            del ep, state, action
            if velocity is not None:
                del velocity
            if effort is not None:
                del effort
            gc.collect()

        # æ›´æ–°è¿›åº¦
        finished.add(ep_idx)
        try:
            progress_path.parent.mkdir(parents=True, exist_ok=True)
            progress_path.write_text(json.dumps({"finished": sorted(finished)}))
        except Exception as e:
            print(f"âš ï¸ Failed to write progress file: {e}")

        # æ‰“å°å½“å‰å†…å­˜æƒ…å†µ
        mem_gb = process.memory_info().rss / (1024 ** 3)
        delta = mem_gb - prev_mem_gb
        print(f"âœ… Episode {ep_idx} done. Memory usage: {mem_gb:.2f} GB (Î” {delta:+.2f} GB)")
        prev_mem_gb = mem_gb

    return dataset


# ========================
# é¡¶å±‚å°è£…
# ========================

def port_aloha(
    raw_dir: Path,
    repo_id: str,
    raw_repo_id: Optional[str] = None,
    task: str = "DEBUG",
    *,
    episodes: Optional[List[int]] = None,
    push_to_hub: bool = False,
    is_mobile: bool = False,
    mode: Literal["video", "image"] = "image",
    dataset_config: DatasetConfig = DEFAULT_DATASET_CONFIG,
):
    raw_dir = Path(raw_dir)
    print(f"\nğŸ“‚ Raw dir: {raw_dir}")
    hdf5_files = sorted(raw_dir.glob("*.hdf5"))
    if not hdf5_files:
        raise FileNotFoundError(f"No .hdf5 files found in {raw_dir}")
    print(f"ğŸ§¾ Episodes found: {len(hdf5_files)}")

    features = build_features(hdf5_files, mode)
    dataset = safe_open_dataset(
        repo_id=repo_id,
        features=features,
        fps=50,
        robot_type="mobile_aloha" if is_mobile else "aloha",
        dataset_config=dataset_config,
    )

    dataset = populate_dataset(
        dataset=dataset,
        hdf5_files=hdf5_files,
        task=task,
        repo_id=repo_id,
        episodes=episodes,
    )

    if push_to_hub:
        dataset.push_to_hub()


if __name__ == "__main__":
    port_aloha(
        raw_dir=Path("/home/eii/aloha-2.0/aloha_data/cut_data/merged_twist_two"),
        repo_id="lyl472324464/twist_two_202511",
        task="Twist off the bottle cap.",
        push_to_hub=False,
        mode="image",
    )
